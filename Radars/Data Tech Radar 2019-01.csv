name,ring,quadrant,isNew,description
Grafana,hold,tools,TRUE,"<a href=""https://grafana.com/"">Grafana</a> was the standard metric graphing and dashboard tool for data center applications. While it is possible to run in AWS, it requires its own instance to run and maintain. Therefore, we put the use of Grafana on hold in favour of DataDog."
RStudio,hold,tools,TRUE,"<a href=""https://rstudio.com/"">RStudio</a> An IDE for R. Some past data science projects were developed in R, RStuidio offers a whole suite of libraries. DS team has fully adopted Python as the development language, which is easier for deployment process, hence RStudio is on hold."
TeamCity,hold,tools,TRUE,"<a href=""https://www.jetbrains.com/teamcity/"">TeamCity</a> is based on a centralized model where all engineering teams use the same installation. Scaling the services, limiting blast-radius and implementing security isolation is very difficult with this model. Although TeamCity is still used heavily within Data Technology teams, we would like to move away from it to FiZZ, Scout24's in-house solution for de-centralized Jenkins."
PyTorch,assess,tools,TRUE,"Developed by Facebook, interesting alternative to TensorFlow"
JupyterLab,assess,tools,TRUE,Next-generation web-based user interface for Project Jupyter
FBProphet,assess,tools,TRUE,"<a href=""https://grafana.com/"">Grafana</a> A library for building Bayesian Structural time series models, developed and actively maintained by Facebook. It is used in evaluating "
Dask,trial,tools,TRUE,"Distributed computing without the overhead of the JVM, used in production"
FiZZ,trial,tools,TRUE,"<a href=""https://docs.cloud.scout24.com/products/fizz/"">FiZZ</a> is a cloud CI/CD solution based on Jenkins and managed by Delivery Engineering. It allows teams to set up their own build and deploy environments without interfering with other teams, while giving them access to a (theoretically) unlimited number of build servers. Jenkins and thus FiZZ allows writing build pipelines as code, making it easy to version control and test the build pipeline together with the code being built."
Jupyter,adopt,tools,TRUE,
Zeppelin,adopt,tools,TRUE,
CloudHealth,adopt,tools,TRUE,"<a href=""https://cloudhealthtech.com/"">CloudHealth</a> is a tool for analysing our AWS costs. It is our main tool for keeping an eye on costs and investigating any anomolies. We use it instead of the built-in cost tracking features of AWS because it can aggregate costs across all our accounts."
Pandas,adopt,tools,TRUE,"Python library that provides high-level data structures and a vast variety of tools for analysis, used everywhere"
DataWario,adopt,tools,TRUE,
Docker,adopt,tools,TRUE,
PAC,adopt,tools,TRUE,Personal Analytics Cluster (PAC) is a tool for running queries on Data Lake. It utilizes Jupyter and Zeppelin notebooks running on an auto-scaling Hadoop cluster. You can write Scala Spark or pySpark jobs and you may also use Hue to run SQL-based queries using Hive. We use it to spike some usecases and adhoc analysis.
AWS CloudFormation,adopt,tools,TRUE,AWS CloudFormation provides a common language to describe and provision all the infrastructure resources in our cloud environment. We use it to have our infrastructure as code  so we can recreate it seamlessly.
R,hold,languages & frameworks,TRUE,"A programming language many data scientists in the industry still use, with emphasis on traditional statistical methods. Similar to RStudio, it is not the choice of development any more at Scout24. "
Python 2,hold,languages & frameworks,TRUE,
Java,hold,languages & frameworks,TRUE,"<a href=""https://go.java"">Java</a> is a programming language, that has long been the standard language of ImmobilienScout24. It was also the language of choice of the Data Platform for a long time, with components like the Hadoop REST API, One Scout User DB, and DataWario being written in Java. Java is still a very good general purpose language, however it is also quite verbose, making code usually harder to read and less concise. It also doesn't support new programming paradigms like Functional Programming as well as other languages like Scala."
Kotlin,assess,languages & frameworks,TRUE,"<a href=""https://kotlinlang.org/"">Kotlin</a> is a relatively young programming language, that has already gained some traction in the industry, for example as the standard language for Android development and by having native support by the Spring Framework. It is based on the Java Virtual Machine which allows for good interoperability with existing Java libraries. The syntax of Kotlin strikes a good balance between Java's verbosity and Scala's conciseness, making it easier to learn than Scala, especially for existing Java developers. Kotlin is being developed by JetBrains, the company behind IntelliJ IDEA, which means that the developer experience in IntelliJ is usually better than with Scala. Spark applications can also be written in Kotlin by using Java SDK, although it is not supported by Zeppelin, yet, i.e. prototyping Spark applications is still easier in Scala."
SQL,adopt,languages & frameworks,TRUE,"<a href=""https://en.wikipedia.org/wiki/SQL"">SQL</a> is a domain-specific language for defining, manipulating and querying data structures. It has its origins as an interface for relational databases, like Oracle and MySQL, but has since been adopted for non-relational datastores as well, for example AWS provides SQL interfaces for Kinesis streams and S3. In addition to that all big data processing frameworks supply an SQL interface, examples include Spark, Flink, Hive and Preto. While all of them have different SQL dialects, there's still a common, standardized base syntax, keeping the learning curve low when switching between frameworks. That being said, SQL should not be used as the hammer that fits every nail, it is not a programming language and rather hard to test. For ETL pipelines, usually other languages are a better choice."
Bash,adopt,languages & frameworks,TRUE,
Scala,adopt,languages & frameworks,TRUE,"Scala is a JVM based, high-level programming laguage combines object-oriented and functional programming in one concise. We use it to implement some parts of our Data Platform like pipelines or tools."
Spark,adopt,languages & frameworks,TRUE,"Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. We use it to build ETL pipelines and to proccess data in scale."
Python 3,adopt,languages & frameworks,TRUE,
TensorFlow,adopt,languages & frameworks,TRUE,"Machine learning framework iwith a great ecosystem, used in production"
Amazon Sagemaker,assess,platforms,TRUE,
Infinity,assess,platforms,TRUE,"<a href=""https://docs.cloud.scout24.com/products/infinity/"">Infinity</a> is Scout24's solution for running applications as Docker containers. The infrastructure for running the containers is managed by the Cloud team, reducing management effort on our side. For example, using Infinity would remove the need for updating AMIs regularly for security reasons. While Infinity is not suitable for workloads running on EMR or in Data Pipeline, it might be usable for the One Scout User DB or other services currently running on EC2 instances managed by our team."
ThoughtSpot,assess,platforms,TRUE,"<a href=""https://www.thoughtspot.com/resources"">ThoughtSpot </a> is business-intelligence analytics search software and a leader in search and AI-driven analytics. It allows for non-technical individuals to conduct a self-service data analysis search. ThoughtSpot includes a machine learning algorithm that presents data suggestions to guide users as input is being typed. It also automatically graphs data sources and joins tables to calculate answers across previously siloed databases. It has a   visualization engine that sorts through possible charts and graphs and presents users with the one best suited to their search. We plan to assess ThoughtSpot because we believe it is a next-generation analytics platform which offers a great business value to our users."
Kylo,assess,platforms,TRUE,"<a href=""https://kylo.io/"">Kylo </a> is Kylo is an open source enterprise-ready data lake management software platform for self-service data ingest and data preparation with integrated metadata management, governance, security and best practices inspired by Think Big’s big data implementation projects. We plan to assess Kylo because we believe it provides an easy self-service solution for data ingestion which will be suitable even for non-technical users, as well as for data preparation with help of visual SQL."
Amazon Redshift,assess,platforms,TRUE,
AWS Glue,assess,platforms,TRUE,
AWS Data Pipeline,trial,platforms,TRUE,"AWS Data Pipeline is a web service that helps to build the process running between different AWS services. With AWS Data Pipeline, data can be accessed, tranformed and processed at scale. ETL jobs can be easily monitored as well."
Amazon Kinesis Streams,trial,platforms,TRUE,
Google Big Query,trial,platforms,TRUE,"Google's Big Query is ideally suited for advanced analysis of our Google Analytics data because there is no need to move the data into our data lake first. However, we leave Big Query in the trial state because the benefits may not overshadow the extra cost in learning and maintainance incurred by having Google Analytics data analysed in a separate environment from the rest of the Data Platform."
Amazon Elasticache,trial,platforms,TRUE,??? likely not Data Science
Presto,trial,platforms,TRUE,
Amazon ECS,trial,platforms,TRUE,
Alation,trial,platforms,TRUE,"<a href=""https://alation.com/"">Alation</a> is the data catalog where everyone in the organization can find the data they need to collaborate. Alation automatically indexes data by source and automatically gathers knowledge about data. Alation uses machine learning to continually improve human understanding. Alation helps to work better together, use data with confidence, improve productivity, and index all data knowledge. Alation currently being used by (DnA) Analysts. After bugs with MicroStrategy connection are fixed, it will be rolled out to broader range of users. "
Amazon DynamoDB,adopt,platforms,TRUE,
DataDog,adopt,platforms,TRUE,"<a href=""https://www.datadoghq.com/"">Datadog</a> is our central monitoring and operational dashboard solution. All systems metrics are either pushed directly to DataDog via the agent or to CloudWatch which in turn gets pushed to DataDog."
AWS Lambda,adopt,platforms,TRUE,Lambda functions can be executed serverlessly. The code uploaded by users will be run and scaled with high availability.  The code can also be triggered by other AWS services.
Amazon EMR,adopt,platforms,TRUE,
Amazon EC2,adopt,platforms,TRUE,
Amazon S3,adopt,platforms,TRUE,
Amazon CloudWatch,adopt,platforms,TRUE,
Amazon Aurora-MySQL,adopt,platforms,TRUE,"For cloud-based infrastructure that necessitates using a relational database, we adopt Amazon Aurora (out of the RDS offering) for superior scalability features and speed. Currently most of our databases in the cloud are MySQL compliant even though this is not a hard requirement and might change in the future to e.g. PostgreSQL compatible Aurora clusters"
Amazon Kinesis Firehose,adopt,platforms,TRUE,
MicroStrategy,adopt,platforms,TRUE,"<a href=""https://www.microstrategy.com/us"">MicroStrategy</a> is an enterprise business intelligence application, which supports interactive dashboards, scorecards, alerts, ad hoc queries, reports scheduling and distribution. MicroStrategy provides flexible self-service solution for advanced analytics and is used by everybody in the company who wants to analyze and visualize their data."
Code reviews,hold,techniques,TRUE,We put code-reviews on hold as we see the benefit of always having multiple people work on tasks together (see pair programming). This fosters natural knowledge sharing and does away with the necessity to have formal reviews
Versioning ML models and data,assess,techniques,TRUE,
Hack days,assess,techniques,TRUE,
Game days,assess,techniques,TRUE,
Gradual rollouts to production,assess,techniques,TRUE,"In order to minimize the user impact on rolling out new changes to our infrastructure, we want to assess techniques that would do this rollout gradually such that we can tightly monitor system behavior and can quickly react in case the infrastructure does not behave as intended"
PRFAQ process,assess,techniques,TRUE,
Survey user satisfaction,assess,techniques,TRUE,
Cleanup Fridays,trial,techniques,TRUE,
Test driven development,trial,techniques,TRUE,"When a bug shows up, it could be adjusted to be a test case. Then the production code will be modified in order to get this test pass."
Monitor system health,trial,techniques,TRUE,
End to end development,trial,techniques,TRUE,
Causal inference with A/B testing,trial,techniques,TRUE,"Causal inference is the process of drawing conclusion about a casual connection based on the conditions of the occurrence of an effect. A/B testing is a common practice of causal inference adopted by the tech industry. There are plenty A/B testing and analysis tools readily available for analysts and PMs, yet very few covers the rigor and scientific basis."
Platform approach,trial,techniques,TRUE,
Micro-tools,trial,techniques,TRUE,"The term ""Micro-tools"" is based on <a href=""https://microservices.io/"">Micro services</a>. A micro service is a system that has only one specific task. To enable a complete usecase, these services would then interact via well-defined interfaces. In the data platform, we usually don't provide many ""services"" but instead focus on tools that make working with data easier for the users. Putting the analogy from micro services to work with micro tools means, that our tools do one job very well. For example the event snapshotter focuses on the snapshotting task, and does not provide the possibility to aggregate metrics, convert data or create tables ontop of the data. For these tasks we provide other tools. This improves usability, because each tool doesn't have many configuration settings, and testability, because there are less possible conditions that can apply. (see also the <a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle>Single responsibility principle""</a>)"
Kanban with regular planning intervals,trial,techniques,TRUE,
Spikes,adopt,techniques,TRUE,"Spike is a good way to gather all the ideas from all team members regarding certain technical topics, such as approaches to tackle certain problems, technology to be applied, etc. "
Allow for remote collaboration,adopt,techniques,TRUE,"We concously choose to have our meetings set up in a way that they can be joined remotely, be it for the purposes of enabling home-office occasionally, or cross-location collaborations between the BER and MUC offices. This also entails the strong reliance on a variety of other tools (like JiRA and Confluence) to make decisions and work transparent to the entire team"
Pair programming,adopt,techniques,TRUE,"Pair programming is an agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently. We use this technique daily bases to preduce better code with fewer defects."
Architecture decision records,adopt,techniques,TRUE,"As a means to continuously improve our processes, we adopt retrospectives. We use them to look back at the previous cycle, determine what went well and what we can do better in the future. "
Retrospectives,adopt,techniques,TRUE,
Pull requests with no review,adopt,techniques,TRUE,"Pull Requests as a general feaure are useful to group a series of commits that delivers a particular feature or solves a task. In particular, one can see at a glance what was changed and why (in combination with comments). However, we do not intend to peer-review these changes before merging them to production as we practice pair-programming and thus will naturally fill in for the purposes of a review"